{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on a point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 6)\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "df = get_data('pointcloud').sample(1000)\n",
    "pca = PCA(n_components=2)\n",
    "df2d = pd.DataFrame(pca.fit_transform(df), columns=list('xy'))\n",
    "df2d.plot(kind='scatter', x='x', y='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on SMS messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "sms = get_data('sms-spam')\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)\n",
    "sms.spam = sms.spam.astype(int)\n",
    "sms.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "tfidf_docs = pd.DataFrame(tfidf_docs, index=index)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.spam.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on SMS Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=16)\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated SVD on SMS Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=16, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors, axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "pca = PCA(n_components=16)\n",
    "pca16_topic_vectors = pca.fit_transform(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca16_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['pca16_spam'] = lda.predict(pca16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDiA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sum([len(casual_tokenize(t)) for t in sms.text]) / len(sms.text), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=sms.text).toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(), counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.loc['sms0'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_docs.loc['sms0'][bow_docs.loc['sms0'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.DataFrame(ldia.components_.T, index=terms, columns=columns)\n",
    "pd.set_option(\"display.max_columns\",16)\n",
    "components.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components.topic4.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors, index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ldia16_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia16_spam'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_docs, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "print(\"Train accuracy:\", round(float(lda.score(X_train, y_train)), 3))\n",
    "print(\"Test accuracy:\", round(float(lda.score(X_test, y_test)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia32 = LDiA(n_components=32, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.n_components)]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors, index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ldia32_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia32_spam'] = lda.predict(ldia32_topic_vectors)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", round(float(lda.score(X_train, y_train)), 3))\n",
    "print(\"Test accuracy:\", round(float(lda.score(X_test, y_test)), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
